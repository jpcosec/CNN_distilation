{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "\n",
    "train_images=np.expand_dims(train_images,axis=3)\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images=np.expand_dims(test_images,axis=3)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\usuario1\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\usuario1\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "\n",
    "inputs = tf.keras.Input(shape=(*IMAGE_SHAPE,))\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=5, padding='SAME', activation=tf.nn.relu)(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=[2, 2], strides=[2, 2], padding=\"SAME\")(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=5, padding='SAME', activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=[2, 2], strides=[2, 2], padding=\"SAME\")(x)\n",
    "x = tf.keras.layers.Conv2D(128, kernel_size=5, padding='SAME', activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.layers.Dense(\n",
    "    84, activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "predictions = tf.layers.Dense(10,activation=tf.nn.softmax)(x)\n",
    "\n",
    "cnn = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "cnn.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn=False\n",
    "if train_cnn:\n",
    "\n",
    "    cnn.fit(train_images, train_labels, epochs=200,\n",
    "          callbacks = [cp_callback])\n",
    "else:\n",
    "    cnn.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 344us/sample - loss: 0.2063 - acc: 0.9872\n",
      "Test accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = cnn.evaluate(test_images, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                526932    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 784,806\n",
      "Trainable params: 784,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class distiller(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, ext_model,lay_num, hidden_size=100):\n",
    "\n",
    "        super(distiller, self).__init__()\n",
    "        self.IMAGE_SHAPE  = [28, 28, 1]\n",
    "\n",
    "        self.FILTER_SHAPE = ext_model.layers[lay_num].output.shape.as_list()[1:]\n",
    "\n",
    "        self.ext_model_layers=ext_model.layers[:lay_num]\n",
    "        for lay in self.ext_model_layers:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        self.ext_post_net=ext_model.layers[lay_num:]\n",
    "        for lay in self.ext_post_net:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        #for layer in intermediate_layer_model.layers:\n",
    "        #    layer.trainable = False\n",
    "\n",
    "\n",
    "        self.rs = tf.keras.layers.Reshape([-1,np.prod(self.IMAGE_SHAPE)])\n",
    "        self.hidden = tf.keras.layers.Dense(hidden_size, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(np.prod(self.FILTER_SHAPE), activation=tf.nn.relu)\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "    \n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        y=self.out(self.hidden(self.rs(inputs)))\n",
    "\n",
    "        if training:\n",
    "            y_ext = inputs\n",
    "            for lay in self.ext_model_layers:\n",
    "                y_ext = lay(y_ext)\n",
    "            y_ext.reshape([-1,y_ext.output.shape.as_list()])\n",
    "            return tf.math.subtract(t,y_ext)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def mix_pred(self,inputs):\n",
    "        \n",
    "        y=self.out(self.hidden(self.rs(inputs)))\n",
    "        y.reshape([-1,self.FILTER_SHAPE])\n",
    "        for lay in self.ext_post_net:\n",
    "                y = lay(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    return tf.mean_square_error(un[0], tf.zeros_like(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_generator(hidden_units,n_test, folder, n_epochs=100):\n",
    "    #cnn.layers[1].output\n",
    "    model = distiller(cnn, 5, hidden_size=hidden_units)\n",
    "    opt=tf.train.AdamOptimizer()#learning_rate=0.01)# Cambiar a lr si se usa tf.keras\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  metrics=['mean_squared_error'],\n",
    "                 optimizer=opt)\n",
    "\n",
    "    checkpoint_path = folder+\"training_distiller\"+str(hidden_units)+\"-\"+str(n_test)+\"/cp.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=0)\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    \n",
    "\n",
    "    shape_out=np.prod(cnn.layers[5].output.shape.as_list()[1:])\n",
    "    model.fit(train_images, \n",
    "              np.zeros([train_images.shape[0],shape_out]), \n",
    "              epochs=n_epochs,\n",
    "              callbacks = [cp_callback],#,es_callback],\n",
    "              verbose=0,)\n",
    "\n",
    "    np.save(folder+\"c5u\"+str(hidden_units)+\"-\"+str(n_test),model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distillators=False\n",
    "if train_distillators:\n",
    "    #units = [10, 100, 500, 780, 790, 1000, 5000, 10000]\n",
    "    units = [50,150,200,250,300,350,400,450]\n",
    "    n_exp = 5\n",
    "    plt.figure()\n",
    "    folder=\"exp3/\"\n",
    "    msg =\"attemp %n with %j units\"\n",
    "\n",
    "    n_epochs = 100\n",
    "    for hidden_units in units:\n",
    "        for i in range(n_exp):\n",
    "            print(msg.replace(\"%n\",str(i)).replace(\"%j\",str(hidden_units)))\n",
    "            training_generator(hidden_units, i, folder, n_epochs=n_epochs)\n",
    "            plt.semilogy(\n",
    "                np.load(folder + \"c5u\" + str(hidden_units) + \"-\" + str(i) + \".npy\"),\n",
    "                label=str(hidden_units),\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.savefig(folder + \"loss_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repiping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distiller(n_unnits):\n",
    "    checkpoint_path = \"training_distiller\"+str(n_unnits)+\"/cp.ckpt\"\n",
    "    model = distiller(cnn, 5, hidden_size=hidden_units)\n",
    "    opt=tf.train.AdamOptimizer()#learning_rate=0.01)# Cambiar a lr si se usa tf.keras\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  metrics=['mean_squared_error'],\n",
    "                 optimizer=opt)\n",
    "    model.load_weights(checkpoint_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled=get_distiller(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([7, 7, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilled.FILTER_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(64)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilled.ext_post_net[0].input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class repiped_distiller(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, ext_model,lay_num, hidden_size=100):\n",
    "\n",
    "        super(repiped_distiller, self).__init__()\n",
    "        self.IMAGE_SHAPE  = [28, 28, 1]\n",
    "\n",
    "        self.FILTER_SHAPE = ext_model.layers[lay_num].output.shape.as_list()[1:]\n",
    "\n",
    "        self.ext_model_layers=ext_model.layers[:lay_num]\n",
    "        for lay in self.ext_model_layers:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        self.ext_post_net=ext_model.layers[lay_num+1:]\n",
    "        for lay in self.ext_post_net:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        #for layer in intermediate_layer_model.layers:\n",
    "        #    layer.trainable = False\n",
    "\n",
    "\n",
    "        self.rs = tf.keras.layers.Reshape([-1,np.prod(self.IMAGE_SHAPE)])\n",
    "        self.hidden = tf.keras.layers.Dense(hidden_size, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(np.prod(self.FILTER_SHAPE), activation=tf.nn.relu)\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "    \n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        y=self.out(self.hidden(self.rs(inputs)))\n",
    "\n",
    "        if training:\n",
    "            y_ext = inputs\n",
    "            for lay in self.ext_model_layers:\n",
    "                y_ext = lay(y_ext)\n",
    "            y_ext.reshape([-1,y_ext.output.shape.as_list()])\n",
    "            return tf.math.subtract(t,y_ext)\n",
    "\n",
    "        self.rs = tf.keras.layers.Reshape([-1,*self.FILTER_SHAPE[1:]  ])\n",
    "        for lay in self.ext_post_net:\n",
    "                y = lay(y)\n",
    "        return y\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    return tf.mean_square_error(un[0], tf.zeros_like(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x261fb961cc0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_unnits=500\n",
    "r_model=repiped_distiller(cnn,5, hidden_size=n_unnits)\n",
    "r_model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint_path = \"training_distiller\"+str(n_unnits)+\"/cp.ckpt\"\n",
    "r_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 74us/sample - loss: 2.4166 - acc: 0.0975\n",
      "Test accuracy: 0.09751666\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = r_model.evaluate(train_images, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension size must be evenly divisible by 53760000 but is 47040000 for 'repiped_distiller_8/reshape_17/Reshape' (op: 'Reshape') with input shapes: [60000,28,28,1], [4] and with input tensors computed as partial shapes: input[1] = [60000,?,7,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1658\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension size must be evenly divisible by 53760000 but is 47040000 for 'repiped_distiller_8/reshape_17/Reshape' (op: 'Reshape') with input shapes: [60000,28,28,1], [4] and with input tensors computed as partial shapes: input[1] = [60000,?,7,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-71286ec40268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# Eager execution on data tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-05b5a7137fa4>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# Eager execution on data tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    437\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     return array_ops.reshape(inputs,\n\u001b[1;32m--> 439\u001b[1;33m                              (array_ops.shape(inputs)[0],) + self.target_shape)\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   7177\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7178\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 7179\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   7180\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7181\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3300\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1823\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\JP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension size must be evenly divisible by 53760000 but is 47040000 for 'repiped_distiller_8/reshape_17/Reshape' (op: 'Reshape') with input shapes: [60000,28,28,1], [4] and with input tensors computed as partial shapes: input[1] = [60000,?,7,128]."
     ]
    }
   ],
   "source": [
    "r_model(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=[1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x25f60d9b390>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25f60d9b400>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25f60d9b7f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25f60a2b828>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25f60d9b9b0>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x25f61047630>,\n",
       " <tensorflow.python.layers.core.Dense at 0x25f62043588>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25f62060da0>,\n",
       " <tensorflow.python.layers.core.Dense at 0x25f62096320>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x261fb8162b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x261fb816278>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x261fb816470>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x25f60d9b390>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25f60d9b400>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25f60d9b7f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25f60a2b828>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x25f60d9b9b0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x25f61020eb8>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x25f61047630>,\n",
       " <tensorflow.python.layers.core.Dense at 0x25f62043588>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x25f62060da0>,\n",
       " <tensorflow.python.layers.core.Dense at 0x25f62096320>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x261a3d632e8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x261a3d63208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x261a3d63828>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilled.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
