{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "\n",
    "train_images=np.expand_dims(train_images,axis=3)\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images=np.expand_dims(test_images,axis=3)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "\n",
    "inputs = tf.keras.Input(shape=(*IMAGE_SHAPE,))\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=5, padding='SAME', activation=tf.nn.relu)(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=[2, 2], strides=[2, 2], padding=\"SAME\")(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=5, padding='SAME', activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=[2, 2], strides=[2, 2], padding=\"SAME\")(x)\n",
    "x = tf.keras.layers.Conv2D(128, kernel_size=5, padding='SAME', activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.layers.Dense(\n",
    "    84, activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "predictions = tf.layers.Dense(10,activation=tf.nn.softmax)(x)\n",
    "\n",
    "cnn = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "cnn.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn=False\n",
    "if train_cnn:\n",
    "\n",
    "    cnn.fit(train_images, train_labels, epochs=200,\n",
    "          callbacks = [cp_callback])\n",
    "else:\n",
    "    cnn.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn.evaluate(test_images, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class distiller(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, ext_model,lay_num, hidden_size=100):\n",
    "\n",
    "        super(distiller, self).__init__()\n",
    "        self.IMAGE_SHAPE  = [28, 28, 1]\n",
    "\n",
    "        self.FILTER_SHAPE = ext_model.layers[lay_num].output.shape.as_list()[1:]\n",
    "\n",
    "        self.ext_model_layers=ext_model.layers[:lay_num]\n",
    "        for lay in self.ext_model_layers:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        self.ext_post_net=ext_model.layers[lay_num:]\n",
    "        for lay in self.ext_post_net:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        #for layer in intermediate_layer_model.layers:\n",
    "        #    layer.trainable = False\n",
    "\n",
    "\n",
    "        self.rs = tf.keras.layers.Reshape([-1,np.prod(self.IMAGE_SHAPE)])\n",
    "        self.hidden = tf.keras.layers.Dense(hidden_size, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(np.prod(self.FILTER_SHAPE), activation=tf.nn.relu)\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "    \n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        y=self.out(self.hidden(self.rs(inputs)))\n",
    "\n",
    "        if training:\n",
    "            y_ext = inputs\n",
    "            for lay in self.ext_model_layers:\n",
    "                y_ext = lay(y_ext)\n",
    "            y_ext.reshape([-1,y_ext.output.shape.as_list()])\n",
    "            return tf.math.subtract(y_ext,t)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def mix_pred(self,inputs):\n",
    "        \n",
    "        y=self.out(self.hidden(self.rs(inputs)))\n",
    "        y.reshape([-1,self.FILTER_SHAPE])\n",
    "        for lay in self.ext_post_net:\n",
    "                y = lay(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    return tf.mean_square_error(un[0], tf.zeros_like(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_generator(hidden_units,n_test, folder, n_epochs=100):\n",
    "    #cnn.layers[1].output\n",
    "    model = distiller(cnn, 5, hidden_size=hidden_units)\n",
    "    opt=tf.train.AdamOptimizer()#learning_rate=0.01)# Cambiar a lr si se usa tf.keras\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  metrics=['mean_squared_error'],\n",
    "                 optimizer=opt)\n",
    "\n",
    "    checkpoint_path = folder+\"training_distiller\"+str(hidden_units)+\"-\"+str(n_test)+\"/cp.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=0)\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    \n",
    "\n",
    "    shape_out=np.prod(cnn.layers[5].output.shape.as_list()[1:])\n",
    "    model.fit(train_images, \n",
    "              np.zeros([train_images.shape[0],shape_out]), \n",
    "              epochs=n_epochs,\n",
    "              callbacks = [cp_callback],#,es_callback],\n",
    "              verbose=0,)\n",
    "\n",
    "    np.save(folder+\"c5u\"+str(hidden_units)+\"-\"+str(n_test),model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distillators=False\n",
    "if train_distillators:\n",
    "    #units = [10, 100, 500, 780, 790, 1000, 5000, 10000]\n",
    "    #units = [50,150,200,250,300,350,400,450]\n",
    "    units = [10,50,150,500,1000]\n",
    "    n_exp = 1\n",
    "    plt.figure()\n",
    "    folder=\"exp4/\"\n",
    "    msg =\"attemp %n with %j units\"\n",
    "\n",
    "    n_epochs = 100\n",
    "    for hidden_units in units:\n",
    "        for i in range(n_exp):\n",
    "            print(msg.replace(\"%n\",str(i)).replace(\"%j\",str(hidden_units)))\n",
    "            training_generator(hidden_units, i, folder, n_epochs=n_epochs)\n",
    "            plt.semilogy(\n",
    "                np.load(folder + \"c5u\" + str(hidden_units) + \"-\" + str(i) + \".npy\"),\n",
    "                label=str(hidden_units),\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.savefig(folder + \"loss_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repiping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distiller(n_units,folder=\"exp4/\"):\n",
    "    checkpoint_path = folder+\"training_distiller\"+str(n_units)+\"/cp.ckpt\"\n",
    "    model = distiller(cnn, 5, hidden_size=n_units)\n",
    "    opt=tf.train.AdamOptimizer()#learning_rate=0.01)# Cambiar a lr si se usa tf.keras\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  metrics=['mean_squared_error'],\n",
    "                 optimizer=opt)\n",
    "    model.load_weights(checkpoint_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class repiped_distiller(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, ext_model,lay_num, hidden_size=100, trainable=False):\n",
    "\n",
    "        super(repiped_distiller, self).__init__()\n",
    "        self.IMAGE_SHAPE  = [28, 28, 1]\n",
    "\n",
    "        self.FILTER_SHAPE = ext_model.layers[lay_num].output.shape.as_list()[1:]\n",
    "        \n",
    "        if self.trainable:\n",
    "            self.ext_model_layers=ext_model.layers[:lay_num]\n",
    "            for lay in self.ext_model_layers:\n",
    "                lay.trainable = False\n",
    "        \n",
    "        self.ext_post_net=ext_model.layers[lay_num+1:]\n",
    "        for lay in self.ext_post_net:\n",
    "            lay.trainable = False\n",
    "        \n",
    "        #for layer in intermediate_layer_model.layers:\n",
    "        #    layer.trainable = False\n",
    "\n",
    "\n",
    "        self.rs = tf.keras.layers.Reshape([-1,np.prod(self.IMAGE_SHAPE)],name=\"distilator_input\")\n",
    "        self.hidden = tf.keras.layers.Dense(hidden_size, activation=tf.nn.relu,name=\"distilator_hidden\")\n",
    "        self.out = tf.keras.layers.Dense(np.prod(self.FILTER_SHAPE), activation=tf.nn.relu,name=\"distilator_output\")\n",
    "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "    \n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        y=self.out(self.hidden(self.rs(inputs)))\n",
    "        if self.trainable:\n",
    "            if training:\n",
    "                y_ext = inputs\n",
    "                for lay in self.ext_model_layers:\n",
    "                    y_ext = lay(y_ext)\n",
    "                y_ext.reshape([-1,y_ext.output.shape.as_list()])\n",
    "                return tf.math.subtract(t,y_ext)\n",
    "\n",
    "        self.rs = tf.keras.layers.Reshape([-1,*self.FILTER_SHAPE[1:]  ])\n",
    "        for lay in self.ext_post_net:\n",
    "                y = lay(y)\n",
    "        return y\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    return tf.mean_square_error(un[0], tf.zeros_like(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unnits=1000\n",
    "trial=0\n",
    "folder=\"exp4/\"\n",
    "\n",
    "r_model=repiped_distiller(cnn,5, hidden_size=n_unnits)\n",
    "\n",
    "r_model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint_path = folder+\"training_distiller%i-%i/cp.ckpt\"%(n_unnits, trial)\n",
    "r_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = r_model.evaluate(train_images[0], train_labels[0])\n",
    "\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_model.predict(train_images[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=r_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_model.layers[10].get_weights())\n",
    "plt.title(\"Pesos intento 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
